{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.15.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from selenium) (2.0.6)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from selenium) (0.23.1)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from trio~=0.17->selenium) (23.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Crawl Data about: \n",
    "- Silver\n",
    "- Crude Oil\n",
    "- SP500\n",
    "- Russel 2000 Index\n",
    "- Platinum\n",
    "- Copper\n",
    "- Dollar Index\n",
    "- CBOE Volatility Index\n",
    "- MSCI EM EFT\n",
    "- EuroUSD\n",
    "- NASDAQ Composite (IXIC)\n",
    "- Nuclear Energy Index\n",
    "(VanEck Uranium+Nuclear Energy ETF (NLR) - năng lượng hạt nhân)\n",
    "- Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(url, start_date_input, end_date_input, column_name='close'):\n",
    "    start_time = time.time()  # Record the start time\n",
    "    \n",
    "    options = Options()     \n",
    "    options.add_experimental_option('detach', True)    \n",
    "    driver = webdriver.Edge(options=options) \n",
    "    \n",
    "    try:\n",
    "        driver.get(url)\n",
    "        \n",
    "        def set_date_and_apply(start_date, end_date):\n",
    "            time.sleep(5)\n",
    "            date_picker = driver.find_element(By.XPATH, '//*[@id=\"Col1-1-HistoricalDataTable-Proxy\"]/section/div[1]/div[1]/div[1]/div/div/div[1]')\n",
    "            date_picker.click()\n",
    "\n",
    "            # Convert datetime objects to strings\n",
    "            start_date_str = start_date.strftime('%d-%m-%Y')\n",
    "            end_date_str = end_date.strftime('%d-%m-%Y')\n",
    "\n",
    "            start_input = driver.find_element(By.XPATH, '//*[@id=\"dropdown-menu\"]/div/div[1]/input')\n",
    "            start_input.clear()\n",
    "            start_input.send_keys(start_date_str)\n",
    "\n",
    "            end_input = driver.find_element(By.XPATH, '//*[@id=\"dropdown-menu\"]/div/div[2]/input')\n",
    "            end_input.clear()\n",
    "            end_input.send_keys(end_date_str)\n",
    "\n",
    "            apply_button = driver.find_element(By.XPATH, '//*[@id=\"dropdown-menu\"]/div/div[3]/button[1]')\n",
    "            apply_button.click()\n",
    "\n",
    "            apply_button = driver.find_element(By.XPATH, '//*[@id=\"Col1-1-HistoricalDataTable-Proxy\"]/section/div[1]/div[1]/button')\n",
    "            apply_button.click()\n",
    "\n",
    "        set_date_and_apply(start_date_input, end_date_input)\n",
    "\n",
    "        # Step3: Scroll down to download all data\n",
    "        time.sleep(5) \n",
    "        previous_length = 0\n",
    "        while True:\n",
    "            bottom = driver.find_element(By.XPATH, '//*[@id=\"Col1-1-HistoricalDataTable-Proxy\"]/section/div[2]/table/tfoot/tr')\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", bottom)\n",
    "            time.sleep(5) \n",
    "\n",
    "            current_length = len(driver.find_elements(By.XPATH, '//*[@id=\"Col1-1-HistoricalDataTable-Proxy\"]/section/div[2]/table/tbody/tr'))\n",
    "            if current_length == previous_length:\n",
    "                break\n",
    "            else:\n",
    "                previous_length = current_length\n",
    "        \n",
    "        rows = driver.find_elements(By.XPATH, '//*[@id=\"Col1-1-HistoricalDataTable-Proxy\"]/section/div[2]/table/tbody/tr')\n",
    "        data = []  \n",
    "        for row in rows:\n",
    "            cells = row.find_elements(By.TAG_NAME, 'td')     \n",
    "            if len(cells) >= 5:\n",
    "                date_text = cells[0].text\n",
    "                close_text = cells[4].text\n",
    "                if close_text == '-':\n",
    "                    close_text = 'NaN'\n",
    "                else:\n",
    "                    close_text = float(close_text.replace(',', ''))\n",
    "                numerical_date = datetime.strptime(date_text, '%b %d, %Y').strftime('%d/%m/%Y')\n",
    "\n",
    "                data.append({'date': numerical_date, column_name: close_text}) \n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        return df\n",
    "    finally:\n",
    "        end_time = time.time()  # Record the end time\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"Execution time for {column_name}: {execution_time} seconds\")\n",
    "        driver.quit()  # Close the WebDriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General \n",
    "Set up from start date to end date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(2010,1,4)\n",
    "end = datetime(2023,11,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_urls = {\n",
    "    'silver': 'https://finance.yahoo.com/quote/SI%3DF/history?p=SI%3DF',\n",
    "    'crude_oil': 'https://finance.yahoo.com/quote/CL%3DF/history?p=CL%3DF',\n",
    "    'SP500': 'https://finance.yahoo.com/quote/%5EGSPC/history?p=%5EGSPC',\n",
    "    'RUT': 'https://finance.yahoo.com/quote/%5ERUT/history?p=%5ERUT',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for silver: 305.9550213813782 seconds\n",
      "Execution time for crude_oil: 302.6884808540344 seconds\n",
      "Execution time for SP500: 298.57992792129517 seconds\n",
      "Execution time for RUT: 308.46917033195496 seconds\n"
     ]
    }
   ],
   "source": [
    "for column_name, url in data_urls.items():\n",
    "    file_path = f'{column_name}.csv'\n",
    "    if not os.path.exists(file_path):\n",
    "        df = get_data(url, start, end, column_name=column_name)\n",
    "        df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RELAXING ....\n"
     ]
    }
   ],
   "source": [
    "print(\"RELAXING ....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_urls1 = {\n",
    "    'platinum': 'https://finance.yahoo.com/quote/PL%3DF/history?p=PL%3DF',\n",
    "    'copper': 'https://finance.yahoo.com/quote/HG%3DF/history?p=HG%3DF',\n",
    "    'DXY': 'https://finance.yahoo.com/quote/DX-Y.NYB/history?p=DX-Y.NYB',\n",
    "    'VIX': 'https://finance.yahoo.com/quote/%5EVIX/history?p=%5EVIX',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for platinum: 306.0257349014282 seconds\n",
      "Execution time for copper: 302.3251111507416 seconds\n",
      "Execution time for DXY: 362.6718144416809 seconds\n",
      "Execution time for VIX: 314.4731693267822 seconds\n"
     ]
    }
   ],
   "source": [
    "for column_name, url in data_urls1.items():\n",
    "    file_path = f'{column_name}.csv'\n",
    "    if not os.path.exists(file_path):\n",
    "        df = get_data(url, start, end, column_name=column_name)\n",
    "        df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RELAXING ....\n"
     ]
    }
   ],
   "source": [
    "print(\"RELAXING ....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_urls2 = {\n",
    "    'MSCI': 'https://finance.yahoo.com/quote/MSCI/history?p=MSCI',\n",
    "    'EURUSD': 'https://finance.yahoo.com/quote/EURUSD%3DX/history?p=EURUSD%3DX',\n",
    "    'NASDAQ': 'https://finance.yahoo.com/quote/%5EIXIC/history?p=%5EIXIC',\n",
    "    'NLR': 'https://finance.yahoo.com/quote/NLR/history?p=NLR',\n",
    "    'rice': 'https://finance.yahoo.com/quote/ZR%3DF/history?p=ZR%3DF'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for MSCI: 301.133362531662 seconds\n",
      "Execution time for EURUSD: 312.63931226730347 seconds\n",
      "Execution time for NASDAQ: 305.1060378551483 seconds\n",
      "Execution time for NLR: 298.0712478160858 seconds\n",
      "Execution time for rice: 312.0010118484497 seconds\n"
     ]
    }
   ],
   "source": [
    "for column_name, url in data_urls2.items():\n",
    "    file_path = f'{column_name}.csv'\n",
    "    if not os.path.exists(file_path):\n",
    "        df = get_data(url, start, end, column_name=column_name)\n",
    "        df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE !!!\n"
     ]
    }
   ],
   "source": [
    "print(\"DONE !!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
